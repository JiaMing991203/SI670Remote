{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668bff61-ec13-4b82-aae4-73ba6923970d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from osgeo import gdal\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aee7e7-a202-45ff-9681-1ffb82181017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tif(input_path):\n",
    "    dataset = gdal.Open(input_path)\n",
    "    width = dataset.RasterXSize\n",
    "    height = dataset.RasterYSize\n",
    "    gdal_array = dataset.ReadAsArray(0, 0, width, height)\n",
    "    band = dataset.RasterCount\n",
    "    proj = dataset.GetProjection()\n",
    "    geotrans = dataset.GetGeoTransform()\n",
    "    \n",
    "    return gdal_array, width, height, band, proj, geotrans, dataset\n",
    "\n",
    "\n",
    "def re_label(data_y):\n",
    "    data_y[data_y<0] = 0\n",
    "    data_y[data_y==11] = 1\n",
    "    data_y[data_y==21] = 2\n",
    "    data_y[data_y==22] = 3\n",
    "    data_y[data_y==23] = 4\n",
    "    data_y[data_y==24] = 5\n",
    "    data_y[data_y==31] = 6\n",
    "    data_y[data_y==41] = 7\n",
    "    data_y[data_y==42] = 8\n",
    "    data_y[data_y==43] = 9\n",
    "    data_y[data_y==52] = 10\n",
    "    data_y[data_y==71] = 11\n",
    "    data_y[data_y==81] = 12\n",
    "    data_y[data_y==82] = 13\n",
    "    data_y[data_y==90] = 14\n",
    "    data_y[data_y==95] = 15\n",
    "    \n",
    "    return data_y\n",
    "\n",
    "\n",
    "def write_geotiff(filename, arr, projection, geotransform):\n",
    "    if arr.dtype == np.float32:\n",
    "        arr_type = gdal.GDT_Float32\n",
    "    else:\n",
    "        arr_type = gdal.GDT_Int32\n",
    "\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    out_ds = driver.Create(filename, arr.shape[1], arr.shape[0], 1, arr_type)\n",
    "    out_ds.SetProjection(projection)\n",
    "    out_ds.SetGeoTransform(geotransform)\n",
    "    band = out_ds.GetRasterBand(1)\n",
    "    band.WriteArray(arr)\n",
    "    band.FlushCache()\n",
    "    band.ComputeStatistics(False)\n",
    "    \n",
    "    \n",
    "def ohe(cluster_label:np.ndarray, k:int):\n",
    "    m, n = cluster_label.shape\n",
    "    res = np.zeros((m,n,k))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            res[i][j][cluster_label[i][j]] = 1\n",
    "    return res\n",
    "\n",
    "\n",
    "def NDVI_calculation(gdal_array):\n",
    "    red_band = gdal_array[:, :, 2]\n",
    "    nir_band = gdal_array[:, :, 3]\n",
    "    \n",
    "    (height, weight) = red_band.shape\n",
    "    \n",
    "    ndvi_band = (nir_band - red_band) / (nir_band + red_band)\n",
    "    ndvi_band = ndvi_band.reshape(height, weight, 1)\n",
    "    \n",
    "    gdal_array_process = np.concatenate((gdal_array, ndvi_band), axis=2)\n",
    "    return gdal_array_process\n",
    "\n",
    "\n",
    "def run_with_clustering(num_clusters=None):\n",
    "    \n",
    "    if (num_clusters == 5) or (num_clusters == 7) or (num_clusters == 15):\n",
    "        cluster_labels = joblib.load('./data/k_cluster_labels.save')\n",
    "        clusters = ohe(cluster_labels[num_clusters], num_clusters)\n",
    "    \n",
    "        gdal_array, width, height, band, proj, geotrans, dataset = read_tif('./data/landsat_extract.tif')\n",
    "        image = np.rollaxis(gdal_array, 0, 3)\n",
    "        \n",
    "        image = NDVI_calculation(image)\n",
    "        \n",
    "        image_seg = np.concatenate((image, clusters), axis=2)\n",
    "        data_x = np.reshape(image_seg, (width * height, band+num_clusters+1))\n",
    "    \n",
    "        return data_x, dataset\n",
    "    else:\n",
    "        gdal_array, width, height, band, proj, geotrans, dataset = read_tif('./data/landsat_extract.tif')\n",
    "        image = np.rollaxis(gdal_array, 0, 3)\n",
    "        image = NDVI_calculation(image)\n",
    "        data_x = np.reshape(image, (width * height, band+1))\n",
    "        \n",
    "        return data_x, dataset\n",
    "\n",
    "    \n",
    "def get_scores(y_label, ypred):\n",
    "    scores = dict()\n",
    "    scores['accuracy'] = accuracy_score(y_label, ypred)\n",
    "    scores['f1_micro'] = f1_score(y_label, ypred, average='micro')\n",
    "    scores['f1_macro'] = f1_score(y_label, ypred, average='macro')\n",
    "    scores['precision_micro'] = precision_score(y_label, ypred, average='micro') \n",
    "    scores['precision_macro'] = precision_score(y_label, ypred, average='macro')\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def export_tiff(data_x, model, height, width, num_clusters):\n",
    "    \n",
    "    dtest_whole = xgb.DMatrix(data_x)\n",
    "    ypred_whole = model.predict(dtest_whole)\n",
    "    ypred_image = np.reshape(ypred_whole, (height, width))\n",
    "\n",
    "    write_geotiff('./output/predict_k_'+str(num_clusters)+'.tiff', ypred_image, proj, geotrans)\n",
    "    \n",
    "    print('finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f027a1-629d-4b3a-9cd7-77f6c3c5cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, dataset = run_with_clustering(7)\n",
    "data_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c656a708-ac03-41f7-b783-cbf95816112e",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cc41c6-f6b8-490b-be3c-4857762c27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelset = gdal.Open(r'./data/nlcd_extract.tif')\n",
    "width = dataset.RasterXSize\n",
    "height = dataset.RasterYSize\n",
    "band = dataset.RasterCount\n",
    "proj = dataset.GetProjection()\n",
    "geotrans = dataset.GetGeoTransform()\n",
    "label_array = labelset.ReadAsArray(0, 0, width, height)  # 获取数据\n",
    "\n",
    "data_y = np.reshape(label_array, (width * height))\n",
    "\n",
    "data_y = re_label(data_y)\n",
    "data_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063127d6-f618-41f5-89a3-2406e0939687",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86828b83-fa8a-4fa6-8f3f-62592e734f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.9, stratify=data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510112c-6595-4bdc-9251-16b6535b1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "del X_train\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0260d44d-c58f-4918-af23-fb4d46144662",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_scaled, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e37b2-6812-442b-8aa4-c2231e6a44e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_scaled\n",
    "del X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5912684e-9c01-4f16-9421-5c655a9e0aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'booster': 'gbtree',\n",
    "          'objective': 'multi:softmax', \n",
    "          'num_class': 16,\n",
    "          'eval_metric': 'auc',  \n",
    "          'max_depth': 7,\n",
    "          'lambda': 15,\n",
    "          'subsample': 0.75,\n",
    "          'colsample_bytree': 0.75,\n",
    "          'min_child_weight': 1,\n",
    "          'eta': 0.025,\n",
    "          'seed': 0,\n",
    "          'nthread': 8,\n",
    "          'verbosity': 1,\n",
    "          'gamma': 0.15,\n",
    "          'learning_rate': 0.01}\n",
    "\n",
    "watchlist = [(dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6187bf-7d85-4c3e-bfc5-085c7a39075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtrain, num_boost_round=30, evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f935cd-5346-4dce-bfe9-4f8778d96aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('xgboost.model')\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "booster = xgb.Booster()\n",
    "booster.load_model('xgboost.model')\n",
    "clf._Booster = booster\n",
    "ypred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f4674e-ecec-4abf-ba7d-7c8c9071ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = get_scores(y_test, ypred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f93f0-7e95-4309-a824-bcfd39ee6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metrics.confusion_matrix(y_test, ypred)\n",
    "sns.heatmap(metric[1:, 1:], cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a329d-3860-4214-919f-1767cb69b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a8263f-a704-4065-8329-c1ecc0a31a52",
   "metadata": {},
   "source": [
    "## Export Tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580083c-7291-4abc-9392-81618d345dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_tiff(data_x, model, height, width, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650f809-9d47-447b-9cd7-5167659244c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
